% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/models.R
\name{fit_tidy_xgb}
\alias{fit_tidy_xgb}
\title{Fit a Tuned XGBoost Regression Model with Tidymodels}
\usage{
fit_tidy_xgb(
  data,
  formula,
  invars,
  strata = NULL,
  nrounds = 1000,
  device = c("cpu", "cuda")
)
}
\arguments{
\item{data}{A data frame containing the training data.}

\item{formula}{A formula specifying the model.}

\item{invars}{A character vector of input variable names (not directly used in the function, but included for interface consistency).}

\item{strata}{An optional character vector specifying the stratification variable for cross-validation. If \code{NULL}, no stratification is applied.}

\item{nrounds}{Integer. Number of boosting rounds (trees) for XGBoost. Default is 1000.}

\item{device}{Character. Device to use for XGBoost training, either "cpu" or "cuda". Default is "cpu".}
}
\value{
A \code{tune_race_anova} object containing the tuning results.
}
\description{
This function fits an XGBoost regression model using the tidymodels framework. It performs PCA on predictors starting with "class_", normalizes all predictors, and tunes hyperparameters (\code{min_n}, \code{tree_depth}, \code{learn_rate}) using a space-filling grid and ANOVA racing. The function returns the tuning results.
}
\details{
\itemize{
\item Applies PCA to predictors starting with "class_" (5 components).
\item Normalizes all predictors.
\item Tunes \code{min_n}, \code{tree_depth}, and \code{learn_rate} over a space-filling grid (size 50).
\item Uses 5-fold cross-validation and evaluates RMSE and R-squared.
}
}
\note{
\code{xgboost} > 3.0.0 is strongly recommended.
}
\examples{
\dontrun{
data()
fit_tidy_xgb(data = my_data, formula = y ~ ., invars = names(my_data)[-1])
}
}
